{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Zero Shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langchain_groq.chat_models import ChatGroq\n",
    "from MakeDataset import X_train,X_test,y_train,y_test\n",
    "import joblib\n",
    "import sklearn as skl\n",
    "Groq_Token = ''  # Do not share this key with anyone\n",
    "\n",
    "\n",
    "groq_models = {\"llama3-70b\": \"llama3-70b-8192\", \"mixtral\": \"mixtral-8x7b-32768\", \"gemma-7b\": \"gemma-7b-it\",\"llama3.1-70b\":\"llama-3.1-70b-versatile\",\"llama3-8b\":\"llama3-8b-8192\",\"llama3.1-8b\":\"llama-3.1-8b-instant\",\"gemma-9b\":\"gemma2-9b-it\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('X_Train_Tsfel.csv')\n",
    "x_test = pd.read_csv('X_Test_Tsfel.csv')\n",
    "activity_label_mapping = {\"WALKING\":1,\"WALKING_UPSTAIRS\":2,\"WALKING_DOWNSTAIRS\":3,\"SITTING\":4,\"STANDING\":5,\"LAYING\":6}\n",
    "\n",
    "grouped_data = x_train.sort_values(by = 'class').groupby('class')\n",
    "\n",
    "csv_tsfel_train_first = grouped_data.get_group(1).to_csv()\n",
    "csv_tsfel_train_second = grouped_data.get_group(2).to_csv()\n",
    "csv_tsfel_train_third = grouped_data.get_group(3).to_csv()\n",
    "csv_tsfel_train_fourth = grouped_data.get_group(4).to_csv()\n",
    "csv_tsfel_train_fifth = grouped_data.get_group(5).to_csv()\n",
    "csv_tsfel_train_sixth = grouped_data.get_group(6).to_csv()\n",
    "\n",
    "csv_tsfel_test = x_test[0:10].to_csv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct answer was: [3 1 2 5 5 1 1 5 3 2]\n",
      "Model predicted: [1, 1, 1, 2, 4, 1, 1, 2, 5, 1]\n",
      "Correct answer was: [6 5 6 5 6 1 6 5 2 5]\n",
      "Model predicted: [1, 1, 3, 2, 3, 2, 3, 2, 2, 1]\n",
      "Correct answer was: [4 3 2 2 1 4 6 4 1 2]\n",
      "Model predicted: [1, 1, 1, 4, 5, 6, 3, 3, 1, 1]\n",
      "Correct answer was: [6 2 4 4 3 6 6 3 1 5]\n",
      "Model predicted: [1, 1, 1, 1, 1, 3, 3, 1, 1, 1]\n",
      "Correct answer was: [3 2 1 4 4 4 5 1 3 3]\n",
      "Model predicted: [1, 1, 1, 4, 5, 6, 1, 1, 1, 1]\n",
      "Total Accuracy turned out to be 17.999999999999996%\n"
     ]
    }
   ],
   "source": [
    "total_accuracies = 0\n",
    "total_iterations = 0\n",
    "num_test_splits = 5\n",
    "\n",
    "activity_label_mapping = {\"WALKING\":1,\"WALKING_UPSTAIRS\":2,\"WALKING_DOWNSTAIRS\":3,\"SITTING\":4,\"STANDING\":5,\"LAYING\":6}\n",
    "\n",
    "for i in range(num_test_splits):\n",
    "    lot_size = 54//num_test_splits\n",
    "    csv_tsfel_test = x_test[lot_size*i:lot_size*(i+1)].to_csv()\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    * You are an activity classification model. \n",
    "    * Your task is to analyze a csv string which will have acceleration values in the x, y and z directions and you have to classify the activity value as \"WALKING\",\"WALKING_UPSTAIRS\",\"WALKING_DOWNSTAIRS\",\"SITTING\",\"STANDING\",\"LAYING\". \n",
    "    * You have a {lot_size} number of rows in the csv string. predict one activity for each of those rows.\n",
    "    * Provide the activity labels ONLY in a space seperated format as the ouput. Do not provide and other text or code or explanation\n",
    "    \n",
    "    Csv_string: {csv_tsfel_test}\n",
    "    \"\"\" \n",
    "\n",
    "\n",
    "    # To use Groq LLMs \n",
    "    model_name = \"llama3-70b\" # We can choose any model from the groq_models dictionary\n",
    "    try:\n",
    "        llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "        answer = llm.invoke(query)\n",
    "        # print(f'Correct Answer was {y_test}')\n",
    "        \n",
    "        \n",
    "        string_answer = answer.content.split()\n",
    "        answer = []\n",
    "        for ans in string_answer:\n",
    "            answer.append(activity_label_mapping[ans])\n",
    "\n",
    "        res = 0\n",
    "        print(f\"Correct answer was: {y_test[lot_size*i:lot_size*(i+1)]}\")\n",
    "        print(f'Model predicted: {answer}')\n",
    "        for j in range(lot_size):\n",
    "            if y_test[lot_size*i + j] == answer[j]:\n",
    "                res += 1\n",
    "        accuracy = res/lot_size\n",
    "        \n",
    "        total_accuracies += accuracy\n",
    "        total_iterations += 1\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "print(f'Total Accuracy turned out to be {100*total_accuracies/total_iterations}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Few Shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct answer was: [3 1 2 5 5 1 1 5 3 2]\n",
      "Model predicted: [1, 5, 1, 4, 2, 1, 1, 5, 1, 2]\n",
      "Correct answer was: [6 5 6 5 6 1 6 5 2 5]\n",
      "Model predicted: [4, 5, 3, 6, 1, 2, 3, 6, 4, 5]\n",
      "Correct answer was: [4 3 2 2 1 4 6 4 1 2]\n",
      "Model predicted: [1, 3, 1, 5, 5, 4, 2, 4, 1, 5]\n",
      "Correct answer was: [6 2 4 4 3 6 6 3 1 5]\n",
      "Model predicted: [3, 1, 6, 1, 3, 6, 4, 6, 2, 1]\n",
      "Correct answer was: [3 2 1 4 4 4 5 1 3 3]\n",
      "Model predicted: [1, 2, 3, 4, 5, 1, 4, 2, 2, 1]\n",
      "T\n",
      "otal Accuracy turned out to be 28.0%\n"
     ]
    }
   ],
   "source": [
    "total_accuracies = 0\n",
    "total_iterations = 0\n",
    "num_test_splits = 5\n",
    "\n",
    "for i in range(num_test_splits):\n",
    "    lot_size = 54//num_test_splits\n",
    "    csv_tsfel_test = x_test[lot_size*i:lot_size*(i+1)].to_csv()\n",
    "    \n",
    "    query = f'''\n",
    "    You are an activity classification model.\n",
    "    \n",
    "    **Instructions:**\n",
    "    1. **Train** a Decision Tree model using the following training data, which includes 6 classes with PCA1 and PCA2 as feature columns and a class as the target value.\n",
    "    2. **Predict** the class for each row in the test data, which consists of {lot_size} rows with PCA1 and PCA2 as feature columns.\n",
    "    3. **Output**: Provide only the {lot_size} predicted activity labels as a single line of space-separated integers. Do not include any additional text, explanations, or code.\n",
    "    \n",
    "    **Training Data:** for first class\n",
    "    {csv_tsfel_train_first}\n",
    "    **Training Data:** for second class\n",
    "    {csv_tsfel_train_second}\n",
    "    **Training Data:** for third class\n",
    "    {csv_tsfel_train_third}\n",
    "    **Training Data:** for fourth class\n",
    "    {csv_tsfel_train_fourth}\n",
    "    **Training Data:** for fifth class\n",
    "    {csv_tsfel_train_fifth}\n",
    "    **Training Data:** for sixth class\n",
    "    {csv_tsfel_train_sixth}\n",
    "    \n",
    "    **Test Data:**\n",
    "    {csv_tsfel_test}\n",
    "    '''\n",
    "\n",
    "    # To use Groq LLMs \n",
    "    model_name = \"llama3-70b\" # We can choose any model from the groq_models dictionary\n",
    "    try:\n",
    "        llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=1)\n",
    "        answer = llm.invoke(query)\n",
    "        # print(f'Correct Answer was {y_test}')\n",
    "        \n",
    "        \n",
    "        answer = list(map(int, answer.content.split()))\n",
    "        res = 0\n",
    "        print(f\"Correct answer was: {y_test[lot_size*i:lot_size*(i+1)]}\")\n",
    "        print(f'Model predicted: {answer}')\n",
    "        for j in range(lot_size):\n",
    "            if y_test[lot_size*i + j] == answer[j]:\n",
    "                res += 1\n",
    "        accuracy = res/lot_size\n",
    "        \n",
    "        total_accuracies += accuracy\n",
    "        total_iterations += 1\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "print(f'\\nTotal Accuracy turned out to be {100*total_accuracies/total_iterations}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which model performs better and why"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few Shot learning turned out to be a better model in general. \n",
    "As opposed to zero shot learning, few shot gives some amount of additional data that the LLM can learn from.\n",
    "This data makes allows the LLM to train its own decision tree and predict values accordingly.\n",
    "This gives us better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Implementation and Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_dt=joblib.load('/Users/rishabhsmacbook/Documents/GitHub/es335-24-fall-assignment-1/Dt_tk3_e.pkl')\n",
    "g_dt=joblib.load('/Users/rishabhsmacbook/Documents/GitHub/es335-24-fall-assignment-1/Dt_tk3_g.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train_Tsfel=pd.read_csv(\"X_Train_Tsfel.csv\")\n",
    "X_Test_Tsfel=pd.read_csv(\"X_Test_Tsfel.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_Train_Tsfel=X_Train_Tsfel.drop(columns=['class'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_Train_Tsfel.columns=[None]*X_Train_Tsfel.shape[1]\n",
    "X_Test_Tsfel.columns=[None]*X_Test_Tsfel.shape[1]\n",
    "scalar=StandardScaler()\n",
    "X_Train_pca_n=scalar.fit_transform(X_Train_Tsfel)\n",
    "X_Test_pca_n=scalar.transform(X_Test_Tsfel)\n",
    "x_tk3=X_Train_pca_n\n",
    "xt_tk3=X_Test_pca_n\n",
    "y_tk3=y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  53.7%\n"
     ]
    }
   ],
   "source": [
    "y_hat=g_dt.predict(xt_tk3)\n",
    "a_g=skl.metrics.accuracy_score(y_test,y_hat)\n",
    "a_g*=100\n",
    "a_g=np.round(a,2)\n",
    "str_a_g=str(a_g)+'%'\n",
    "print(\"Accuracy : \",str_a_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  46.3%\n"
     ]
    }
   ],
   "source": [
    "y_hat=e_dt.predict(xt_tk3)\n",
    "a_e=skl.metrics.accuracy_score(y_test,y_hat)\n",
    "a_e*=100\n",
    "a_e=np.round(a_e,2)\n",
    "str_a_e=str(a_e)+'%'\n",
    "print(\"Accuracy : \",str_a_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which method performs better and why"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Decision Tree gives a better accuracy compared to Few Shot Learning\n",
    "\n",
    "This is because:\n",
    "\n",
    "The decision tree is a more direct method to classify the data whereas the LLM will first first read the instructions, use the training data and train a seperate classification model to classify further input. Any errors in understanding the instructions or understanding the data would be carried foward by the LLM when it train a classification model to predict new values for the test set.\n",
    "\n",
    "Secondly, fewer data points can be provided to the LLM due to the rate limit restrictions. This might lead to the LLM predicting a model that overfits the training data but fails on the test data. There is no such restriction in training data size when we train a decision tree. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations of Zero Shot Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ZSL tries to recognize activities it has never seen before by using descriptions or general information about them. \n",
    " \n",
    " If these descriptions aren't detailed or accurate enough, \n",
    " it can be hard for the system to match them with the actual movement patterns recorded by the accelrometer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations of Few Shot Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FSL learns from only a few examples of each activity. \n",
    "\n",
    "If those examples donâ€™t cover all the different ways the activity might be performed (like different styles or speeds), the system might not learn enough to identify the activity correctly in new situations.\n",
    "\n",
    "The LLM might also tend to overfit to the data that it has learnt from due to the limit on the data that can be provided to the LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quesiton 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>For this task, we will train the LLM using the first 5 activities as training data and the 6th activity as the unknown activity which the LLM will never have come accross previously.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = x_train.sort_values(by = 'class').groupby('class')\n",
    "len_sixth_activity = len(grouped_data.get_group(6))\n",
    "unknown_activity = grouped_data.get_group(6)[['pca1', 'pca2']].to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 3 3 3 3 3\n"
     ]
    }
   ],
   "source": [
    "num_test_splits = 5\n",
    "lot_size = len_sixth_activity\n",
    "\n",
    "query = f'''\n",
    "You are an activity classification model.\n",
    "\n",
    "**Instructions:**\n",
    "1. **Train** a Decision Tree model using the following training data, which includes 5 classes with PCA1 and PCA2 as feature columns and a class as the target value.\n",
    "2. **Predict** the class for each row in the test data, which consists of {lot_size} rows with PCA1 and PCA2 as feature columns.\n",
    "3. **Output**: Provide only the {lot_size} predicted activity labels as a single line of space-separated integers. Do not include any additional text, explanations, or code.\n",
    "\n",
    "**Training Data:** for first class\n",
    "{csv_tsfel_train_first}\n",
    "**Training Data:** for second class\n",
    "{csv_tsfel_train_second}\n",
    "**Training Data:** for third class\n",
    "{csv_tsfel_train_third}\n",
    "**Training Data:** for fourth class\n",
    "{csv_tsfel_train_fourth}\n",
    "**Training Data:** for fifth class\n",
    "{csv_tsfel_train_fifth}\n",
    "**Training Data:** for sixth class\n",
    "\n",
    "**Test Data:**\n",
    "{unknown_activity}\n",
    "'''\n",
    "    \n",
    "model_name = \"llama3-70b\" \n",
    "try:\n",
    "    llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=1)\n",
    "    answer = llm.invoke(query)\n",
    "    \n",
    "    print(answer.content)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the LLM wrongly predicts the activity that it has never seen before\n",
    "\n",
    "It is more or less consistent with the wrong answer. \n",
    "\n",
    "This might probably be because the LLM has been restricted to classify data from the other 5 classes\n",
    "\n",
    "Therefore, the LLM tries to match the unknown different class to the nearest common class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
