{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Zero Shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (126, 500, 3)\n",
      "Testing data shape:  (54, 500, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langchain_groq.chat_models import ChatGroq\n",
    "from MakeDataset import X_train,X_test,y_train,y_test\n",
    "\n",
    "\n",
    "Groq_Token = ''  # Do not share this key with anyone\n",
    "\n",
    "\n",
    "groq_models = {\"llama3-70b\": \"llama3-70b-8192\", \"mixtral\": \"mixtral-8x7b-32768\", \"gemma-7b\": \"gemma-7b-it\",\"llama3.1-70b\":\"llama-3.1-70b-versatile\",\"llama3-8b\":\"llama3-8b-8192\",\"llama3.1-8b\":\"llama-3.1-8b-instant\",\"gemma-9b\":\"gemma2-9b-it\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('X_Train_Tsfel.csv')\n",
    "x_test = pd.read_csv('X_Test_Tsfel.csv')\n",
    "activity_label_mapping = {\"WALKING\":1,\"WALKING_UPSTAIRS\":2,\"WALKING_DOWNSTAIRS\":3,\"SITTING\":4,\"STANDING\":5,\"LAYING\":6}\n",
    "\n",
    "grouped_data = x_train.sort_values(by = 'class').groupby('class')\n",
    "\n",
    "csv_tsfel_train_first = grouped_data.get_group(1).to_csv()\n",
    "csv_tsfel_train_second = grouped_data.get_group(2).to_csv()\n",
    "csv_tsfel_train_third = grouped_data.get_group(3).to_csv()\n",
    "csv_tsfel_train_fourth = grouped_data.get_group(4).to_csv()\n",
    "csv_tsfel_train_fifth = grouped_data.get_group(5).to_csv()\n",
    "csv_tsfel_train_sixth = grouped_data.get_group(6).to_csv()\n",
    "\n",
    "csv_tsfel_test = x_test[0:10].to_csv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct answer was: [3 1 2 5 5 1 1 5 3 2]\n",
      "Model predicted: [1, 1, 1, 2, 4, 1, 1, 2, 5, 1]\n",
      "Correct answer was: [6 5 6 5 6 1 6 5 2 5]\n",
      "Model predicted: [1, 1, 3, 2, 3, 2, 3, 2, 2, 1]\n",
      "Correct answer was: [4 3 2 2 1 4 6 4 1 2]\n",
      "Model predicted: [1, 1, 1, 4, 5, 6, 3, 3, 1, 1]\n",
      "Correct answer was: [6 2 4 4 3 6 6 3 1 5]\n",
      "Model predicted: [1, 1, 1, 1, 1, 3, 3, 1, 1, 1]\n",
      "Correct answer was: [3 2 1 4 4 4 5 1 3 3]\n",
      "Model predicted: [1, 1, 1, 4, 5, 6, 1, 1, 1, 1]\n",
      "Total Accuracy turned out to be 17.999999999999996%\n"
     ]
    }
   ],
   "source": [
    "total_accuracies = 0\n",
    "total_iterations = 0\n",
    "num_test_splits = 5\n",
    "\n",
    "activity_label_mapping = {\"WALKING\":1,\"WALKING_UPSTAIRS\":2,\"WALKING_DOWNSTAIRS\":3,\"SITTING\":4,\"STANDING\":5,\"LAYING\":6}\n",
    "\n",
    "for i in range(num_test_splits):\n",
    "    lot_size = 54//num_test_splits\n",
    "    csv_tsfel_test = x_test[lot_size*i:lot_size*(i+1)].to_csv()\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    * You are an activity classification model. \n",
    "    * Your task is to analyze a csv string which will have acceleration values in the x, y and z directions and you have to classify the activity value as \"WALKING\",\"WALKING_UPSTAIRS\",\"WALKING_DOWNSTAIRS\",\"SITTING\",\"STANDING\",\"LAYING\". \n",
    "    * You have a {lot_size} number of rows in the csv string. predict one activity for each of those rows.\n",
    "    * Provide the activity labels ONLY in a space seperated format as the ouput. Do not provide and other text or code or explanation\n",
    "    \n",
    "    Csv_string: {csv_tsfel_test}\n",
    "    \"\"\" \n",
    "\n",
    "\n",
    "    # To use Groq LLMs \n",
    "    model_name = \"llama3-70b\" # We can choose any model from the groq_models dictionary\n",
    "    try:\n",
    "        llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "        answer = llm.invoke(query)\n",
    "        # print(f'Correct Answer was {y_test}')\n",
    "        \n",
    "        \n",
    "        string_answer = answer.content.split()\n",
    "        answer = []\n",
    "        for ans in string_answer:\n",
    "            answer.append(activity_label_mapping[ans])\n",
    "\n",
    "        res = 0\n",
    "        print(f\"Correct answer was: {y_test[lot_size*i:lot_size*(i+1)]}\")\n",
    "        print(f'Model predicted: {answer}')\n",
    "        for j in range(lot_size):\n",
    "            if y_test[lot_size*i + j] == answer[j]:\n",
    "                res += 1\n",
    "        accuracy = res/lot_size\n",
    "        \n",
    "        total_accuracies += accuracy\n",
    "        total_iterations += 1\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "print(f'Total Accuracy turned out to be {100*total_accuracies/total_iterations}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Few Shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct answer was: [3 1 2 5 5 1 1 5 3 2]\n",
      "Model predicted: [1, 5, 1, 4, 2, 1, 1, 5, 1, 2]\n",
      "Correct answer was: [6 5 6 5 6 1 6 5 2 5]\n",
      "Model predicted: [4, 5, 3, 6, 1, 2, 3, 6, 4, 5]\n",
      "Correct answer was: [4 3 2 2 1 4 6 4 1 2]\n",
      "Model predicted: [1, 3, 1, 5, 5, 4, 2, 4, 1, 5]\n",
      "Correct answer was: [6 2 4 4 3 6 6 3 1 5]\n",
      "Model predicted: [3, 1, 6, 1, 3, 6, 4, 6, 2, 1]\n",
      "Correct answer was: [3 2 1 4 4 4 5 1 3 3]\n",
      "Model predicted: [1, 2, 3, 4, 5, 1, 4, 2, 2, 1]\n",
      "T\n",
      "otal Accuracy turned out to be 28.0%\n"
     ]
    }
   ],
   "source": [
    "total_accuracies = 0\n",
    "total_iterations = 0\n",
    "num_test_splits = 5\n",
    "\n",
    "for i in range(num_test_splits):\n",
    "    lot_size = 54//num_test_splits\n",
    "    csv_tsfel_test = x_test[lot_size*i:lot_size*(i+1)].to_csv()\n",
    "    \n",
    "    query = f'''\n",
    "    You are an activity classification model.\n",
    "    \n",
    "    **Instructions:**\n",
    "    1. **Train** a Decision Tree model using the following training data, which includes 6 classes with PCA1 and PCA2 as feature columns and a class as the target value.\n",
    "    2. **Predict** the class for each row in the test data, which consists of {lot_size} rows with PCA1 and PCA2 as feature columns.\n",
    "    3. **Output**: Provide only the {lot_size} predicted activity labels as a single line of space-separated integers. Do not include any additional text, explanations, or code.\n",
    "    \n",
    "    **Training Data:** for first class\n",
    "    {csv_tsfel_train_first}\n",
    "    **Training Data:** for second class\n",
    "    {csv_tsfel_train_second}\n",
    "    **Training Data:** for third class\n",
    "    {csv_tsfel_train_third}\n",
    "    **Training Data:** for fourth class\n",
    "    {csv_tsfel_train_fourth}\n",
    "    **Training Data:** for fifth class\n",
    "    {csv_tsfel_train_fifth}\n",
    "    **Training Data:** for sixth class\n",
    "    {csv_tsfel_train_sixth}\n",
    "    \n",
    "    **Test Data:**\n",
    "    {csv_tsfel_test}\n",
    "    '''\n",
    "\n",
    "    # To use Groq LLMs \n",
    "    model_name = \"llama3-70b\" # We can choose any model from the groq_models dictionary\n",
    "    try:\n",
    "        llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=1)\n",
    "        answer = llm.invoke(query)\n",
    "        # print(f'Correct Answer was {y_test}')\n",
    "        \n",
    "        \n",
    "        answer = list(map(int, answer.content.split()))\n",
    "        res = 0\n",
    "        print(f\"Correct answer was: {y_test[lot_size*i:lot_size*(i+1)]}\")\n",
    "        print(f'Model predicted: {answer}')\n",
    "        for j in range(lot_size):\n",
    "            if y_test[lot_size*i + j] == answer[j]:\n",
    "                res += 1\n",
    "        accuracy = res/lot_size\n",
    "        \n",
    "        total_accuracies += accuracy\n",
    "        total_iterations += 1\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "print(f'\\nTotal Accuracy turned out to be {100*total_accuracies/total_iterations}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which model performs better and why"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few Shot learning turned out to be a better model in general. \n",
    "As opposed to zero shot learning, few shot gives some amount of additional data that the LLM can learn from.\n",
    "This data makes allows the LLM to train its own decision tree and predict values accordingly.\n",
    "This gives us better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations of Zero Shot Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ZSL tries to recognize activities it has never seen before by using descriptions or general information about them. \n",
    " \n",
    " If these descriptions aren't detailed or accurate enough, \n",
    " it can be hard for the system to match them with the actual movement patterns recorded by the accelrometer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations of Few Shot Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FSL learns from only a few examples of each activity. \n",
    "\n",
    "If those examples donâ€™t cover all the different ways the activity might be performed (like different styles or speeds), the system might not learn enough to identify the activity correctly in new situations.\n",
    "\n",
    "The LLM might also tend to overfit to the data that it has learnt from due to the limit on the data that can be provided to the LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quesiton 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = x_train.sort_values(by = 'class').groupby('class')\n",
    "len_sixth_activity = len(grouped_data.get_group(6))\n",
    "unknown_activity = grouped_data.get_group(6)[['pca1', 'pca2']].to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 3 3 3 3 3\n"
     ]
    }
   ],
   "source": [
    "num_test_splits = 5\n",
    "lot_size = len_sixth_activity\n",
    "\n",
    "query = f'''\n",
    "You are an activity classification model.\n",
    "\n",
    "**Instructions:**\n",
    "1. **Train** a Decision Tree model using the following training data, which includes 5 classes with PCA1 and PCA2 as feature columns and a class as the target value.\n",
    "2. **Predict** the class for each row in the test data, which consists of {lot_size} rows with PCA1 and PCA2 as feature columns.\n",
    "3. **Output**: Provide only the {lot_size} predicted activity labels as a single line of space-separated integers. Do not include any additional text, explanations, or code.\n",
    "\n",
    "**Training Data:** for first class\n",
    "{csv_tsfel_train_first}\n",
    "**Training Data:** for second class\n",
    "{csv_tsfel_train_second}\n",
    "**Training Data:** for third class\n",
    "{csv_tsfel_train_third}\n",
    "**Training Data:** for fourth class\n",
    "{csv_tsfel_train_fourth}\n",
    "**Training Data:** for fifth class\n",
    "{csv_tsfel_train_fifth}\n",
    "**Training Data:** for sixth class\n",
    "\n",
    "**Test Data:**\n",
    "{unknown_activity}\n",
    "'''\n",
    "    \n",
    "model_name = \"llama3-70b\" \n",
    "try:\n",
    "    llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=1)\n",
    "    answer = llm.invoke(query)\n",
    "    \n",
    "    print(answer.content)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the LLM wrongly predicts the activity that it has never seen before\n",
    "\n",
    "It is more or less consistent with the wrong answer. \n",
    "\n",
    "This might probably be because the LLM has been restricted to classify data from the other 5 classes\n",
    "\n",
    "Therefore, the LLM tries to match the unknown different class to the nearest common class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         pca1      pca2  class\n",
      "0    3.321976  0.402108      2\n",
      "1   -6.726024 -3.189344      6\n",
      "2   -1.273788  3.804777      5\n",
      "3    3.529102 -0.800639      2\n",
      "4    2.759309  0.495436      2\n",
      "..        ...       ...    ...\n",
      "121  3.900801 -0.642566      1\n",
      "122 -4.515600  4.547864      4\n",
      "123 -7.149338 -3.553792      6\n",
      "124  2.391431  0.445788      2\n",
      "125  2.341533  0.635007      2\n",
      "\n",
      "[126 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Creating the Random Data\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "dt=joblib.load('t2_dt1_g.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "BaseDecisionTree.predict() missing 1 required positional argument: 'X'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_hat\u001b[38;5;241m=\u001b[39m\u001b[43mdt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: BaseDecisionTree.predict() missing 1 required positional argument: 'X'"
     ]
    }
   ],
   "source": [
    "y_hat=dt.predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
